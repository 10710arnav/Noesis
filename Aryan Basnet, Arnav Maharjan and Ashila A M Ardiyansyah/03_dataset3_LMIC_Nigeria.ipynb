{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10710arnav/Noesis/blob/main/Aryan%20Basnet%2C%20Arnav%20Maharjan%20and%20Ashila%20A%20M%20Ardiyansyah/03_dataset3_LMIC_Nigeria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NOTE ON RUNTIME AND OUTPUTS**\n",
        "\n",
        "# Google Colab may have disconnected or reset the runtime during long training sessions, crashes, or memory interruptions. When this occurred, some previously displayed outputs in the notebook were no longer visible. However, all results remained saved and logged correctly. Each model’s complete metrics and metadata were stored as JSON files in my Google Drive folder:\n",
        "\n",
        "# [https://drive.google.com/drive/folders/1ejlJaZhHEBm-1khLBJ--mbG2pg5TZHoJ?usp=sharing](https://drive.google.com/drive/folders/1ejlJaZhHEBm-1khLBJ--mbG2pg5TZHoJ?usp=sharing)\n",
        "\n",
        "# These JSON files contain the full and reliable outputs for all models across all datasets, even if certain notebook outputs were lost due to runtime resets."
      ],
      "metadata": {
        "id": "OPoaGyYGbyK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================\n",
        "# SETUP: Freeze all package versions\n",
        "# ==============================\n",
        "Ensure reproducibility by installing the exact versions of packages used in these notebooks. This includes pre-installed packages in Colab.\n",
        "\n",
        "The packages and versions used are:\n",
        "\n",
        "- numpy==1.25.2\n",
        "- pandas==2.1.1\n",
        "- matplotlib==3.8.0\n",
        "- seaborn==0.12.2\n",
        "- scikit-learn==1.3.2\n",
        "- tensorflow==2.15.0\n",
        "- keras==2.15.0\n",
        "- scipy==1.11.2\n",
        "- opencv-python==4.9.0.73\n",
        "- Pillow==10.0.1\n",
        "- h5py==3.9.0\n",
        "- google-colab==2.0.0"
      ],
      "metadata": {
        "id": "GAwBTr8l8tpU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVGPTqgHYX1g",
        "outputId": "64d16691-1fd9-48d0-cd4a-9e5cd2c8aedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: dataset3_nigeria_chest_xray\n",
            "Income Level: LMIC\n",
            "Classes: Normal, Pneumonia, Tuberculosis (COVID-19 dropped)\n",
            "Mounted at /content/drive\n",
            "Downloading dataset...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/aminumusa/nigeria-chest-x-ray-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 241M/241M [00:07<00:00, 34.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/aminumusa/nigeria-chest-x-ray-dataset/versions/1\n",
            "\n",
            "Dataset structure:\n",
            "1/\n",
            "  my_dataset/\n",
            "    train_folder/\n",
            "      PNEUMONIA/\n",
            "        Viral Pneumonia-439.png\n",
            "        Viral Pneumonia-329.png\n",
            "        Viral Pneumonia-8.png\n",
            "        Viral Pneumonia-334.png\n",
            "        Viral Pneumonia-169.png\n",
            "        ... and 495 more files\n",
            "      COVID/\n",
            "        COVID-463.png\n",
            "        COVID-176.png\n",
            "        COVID-354.png\n",
            "        COVID-340.png\n",
            "        COVID-467.png\n",
            "        ... and 495 more files\n",
            "      TB/\n",
            "        Tuberculosis-251.png\n",
            "        Tuberculosis-119.png\n",
            "        Tuberculosis-451.png\n",
            "        Tuberculosis-12.png\n",
            "        Tuberculosis-327.png\n",
            "        ... and 495 more files\n",
            "      NORMAL/\n",
            "        Normal-528.png\n",
            "        Normal-308.png\n",
            "        Normal-272.png\n",
            "        Normal-430.png\n",
            "        Normal-503.png\n",
            "        ... and 495 more files\n",
            "    test_folder/\n",
            "      PNEUMONIA/\n",
            "        Viral Pneumonia-579.png\n",
            "        Viral Pneumonia-589.png\n",
            "        Viral Pneumonia-517.png\n",
            "        Viral Pneumonia-622.png\n",
            "        Viral Pneumonia-645.png\n",
            "        ... and 145 more files\n",
            "      COVID/\n",
            "        COVID-613.png\n",
            "        COVID-521.png\n",
            "        COVID-547.png\n",
            "        COVID-610.png\n",
            "        COVID-567.png\n",
            "        ... and 145 more files\n",
            "      TB/\n",
            "        Tuberculosis-601.png\n",
            "        Tuberculosis-645.png\n",
            "        Tuberculosis-583.png\n",
            "        Tuberculosis-542.png\n",
            "        Tuberculosis-650.png\n",
            "        ... and 145 more files\n",
            "      NORMAL/\n",
            "        Normal-53.png\n",
            "        Normal-39.png\n",
            "        Normal-67.png\n",
            "        Normal-70.png\n",
            "        Normal-96.png\n",
            "        ... and 145 more files\n",
            "\n",
            "Organizing data into train/val/test splits...\n",
            "NOTE: Dropping all COVID-19 images as per project requirements\n",
            "\n",
            "Found images:\n",
            "  Normal: 650\n",
            "  Pneumonia: 650\n",
            "  TB: 650\n",
            "  COVID-19 (dropped): 650\n",
            "\n",
            "Normal split: Train=454, Val=97, Test=99\n",
            "\n",
            "Pneumonia split: Train=454, Val=97, Test=99\n",
            "\n",
            "TB split: Train=454, Val=97, Test=99\n",
            "\n",
            "Checking directories:\n",
            "Train dir exists: True\n",
            "Val dir exists: True\n",
            "Test dir exists: True\n",
            "Found 1362 images belonging to 3 classes.\n",
            "Found 291 images belonging to 3 classes.\n",
            "Found 297 images belonging to 3 classes.\n",
            "\n",
            "Training samples: 1362\n",
            "Validation samples: 291\n",
            "Test samples: 297\n",
            "Classes found: {'Normal': 0, 'Pneumonia': 1, 'TB': 2}\n",
            "\n",
            "==================================================\n",
            "Training BaselineCNN\n",
            "==================================================\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - accuracy: 0.4781 - loss: 1.3575 - val_accuracy: 0.8213 - val_loss: 0.4418\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 4s/step - accuracy: 0.8010 - loss: 0.4941 - val_accuracy: 0.8866 - val_loss: 0.2494\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 4s/step - accuracy: 0.8744 - loss: 0.3220 - val_accuracy: 0.8935 - val_loss: 0.2735\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 4s/step - accuracy: 0.8741 - loss: 0.3329 - val_accuracy: 0.9313 - val_loss: 0.1970\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 4s/step - accuracy: 0.8607 - loss: 0.3509 - val_accuracy: 0.9244 - val_loss: 0.1923\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 4s/step - accuracy: 0.8835 - loss: 0.3183 - val_accuracy: 0.9278 - val_loss: 0.2140\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 4s/step - accuracy: 0.8890 - loss: 0.2740 - val_accuracy: 0.9107 - val_loss: 0.1920\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - accuracy: 0.8824 - loss: 0.2825 - val_accuracy: 0.9244 - val_loss: 0.2041\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 4s/step - accuracy: 0.9187 - loss: 0.2261 - val_accuracy: 0.9141 - val_loss: 0.2800\n",
            "Epoch 10/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 4s/step - accuracy: 0.9108 - loss: 0.2586 - val_accuracy: 0.9175 - val_loss: 0.2307\n",
            "Epoch 11/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 4s/step - accuracy: 0.8906 - loss: 0.3150 - val_accuracy: 0.9519 - val_loss: 0.1534\n",
            "Epoch 12/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 4s/step - accuracy: 0.8952 - loss: 0.2757 - val_accuracy: 0.9175 - val_loss: 0.1799\n",
            "Epoch 13/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - accuracy: 0.9232 - loss: 0.2373 - val_accuracy: 0.9313 - val_loss: 0.1763\n",
            "Epoch 14/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 4s/step - accuracy: 0.8187 - loss: 0.5098 - val_accuracy: 0.8316 - val_loss: 0.4404\n",
            "Epoch 15/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 4s/step - accuracy: 0.8410 - loss: 0.3961 - val_accuracy: 0.9175 - val_loss: 0.2299\n",
            "Epoch 16/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 4s/step - accuracy: 0.8448 - loss: 0.3540 - val_accuracy: 0.9038 - val_loss: 0.2488\n",
            "\n",
            "Evaluating on test set...\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 826ms/step\n",
            "\n",
            "BaselineCNN Results:\n",
            "F1 Scores per class: [0.9134615384615384, 0.9651741293532339, 0.8972972972972973]\n",
            "Weighted F1 Score: 0.9253\n",
            "Training time: 46.38 minutes\n",
            "Parameters: 11,132,163\n",
            "Results saved to: /content/drive/MyDrive/xray_research_results/dataset3_nigeria_chest_xray_LMIC_BaselineCNN_results.json\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "\n",
            "==================================================\n",
            "Training MobileNetV2\n",
            "==================================================\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.7199 - loss: 0.6706 - val_accuracy: 0.9416 - val_loss: 0.1882\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9525 - loss: 0.1257 - val_accuracy: 0.9485 - val_loss: 0.1800\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 3s/step - accuracy: 0.9779 - loss: 0.0754 - val_accuracy: 0.9519 - val_loss: 0.1441\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.9700 - loss: 0.0764 - val_accuracy: 0.9553 - val_loss: 0.1114\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.9706 - loss: 0.0784 - val_accuracy: 0.9485 - val_loss: 0.1958\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 2s/step - accuracy: 0.9828 - loss: 0.0686 - val_accuracy: 0.9416 - val_loss: 0.1993\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.9710 - loss: 0.0916 - val_accuracy: 0.9588 - val_loss: 0.1386\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.9789 - loss: 0.0567 - val_accuracy: 0.9485 - val_loss: 0.1825\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.9894 - loss: 0.0351 - val_accuracy: 0.9553 - val_loss: 0.1261\n",
            "\n",
            "Evaluating on test set...\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step\n",
            "\n",
            "MobileNetV2 Results:\n",
            "F1 Scores per class: [0.9705882352941176, 0.98, 0.9578947368421052]\n",
            "Weighted F1 Score: 0.9695\n",
            "Training time: 14.85 minutes\n",
            "Parameters: 2,422,339\n",
            "Results saved to: /content/drive/MyDrive/xray_research_results/dataset3_nigeria_chest_xray_LMIC_MobileNetV2_results.json\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "\n",
            "==================================================\n",
            "Training EfficientNetB0\n",
            "==================================================\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - accuracy: 0.3322 - loss: 1.1409 - val_accuracy: 0.3333 - val_loss: 1.1082\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.3519 - loss: 1.1091 - val_accuracy: 0.3333 - val_loss: 1.1001\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.3143 - loss: 1.1031 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 3s/step - accuracy: 0.3456 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - accuracy: 0.3418 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.3132 - loss: 1.0987 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.3524 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 8/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.3280 - loss: 1.0987 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 9/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 4s/step - accuracy: 0.3295 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 10/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.3186 - loss: 1.0987 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 11/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.2897 - loss: 1.0987 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 12/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - accuracy: 0.3388 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 13/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.3422 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 14/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.3537 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 15/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - accuracy: 0.3313 - loss: 1.0986 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "\n",
            "Evaluating on test set...\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step\n",
            "\n",
            "EfficientNetB0 Results:\n",
            "F1 Scores per class: [0.0, 0.5, 0.0]\n",
            "Weighted F1 Score: 0.1667\n",
            "Training time: 36.47 minutes\n",
            "Parameters: 4,213,926\n",
            "Results saved to: /content/drive/MyDrive/xray_research_results/dataset3_nigeria_chest_xray_LMIC_EfficientNetB0_results.json\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "\n",
            "==================================================\n",
            "Training ResNet50\n",
            "==================================================\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 8s/step - accuracy: 0.3375 - loss: 1.2834 - val_accuracy: 0.3333 - val_loss: 1.0933\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 7s/step - accuracy: 0.3196 - loss: 1.1123 - val_accuracy: 0.4021 - val_loss: 1.0953\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 8s/step - accuracy: 0.3389 - loss: 1.1017 - val_accuracy: 0.3333 - val_loss: 1.0961\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 7s/step - accuracy: 0.3555 - loss: 1.0965 - val_accuracy: 0.3333 - val_loss: 1.0982\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 8s/step - accuracy: 0.3325 - loss: 1.1002 - val_accuracy: 0.3333 - val_loss: 1.0986\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3328 - loss: 1.0986"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# CHEST X-RAY CLASSIFICATION - DATASET 3\n",
        "# NIGERIA CHEST X-RAY DATABASE\n",
        "# ==========================================\n",
        "\n",
        "# STEP 1: METADATA\n",
        "DATASET_NAME = \"dataset3_nigeria_chest_xray\"\n",
        "COUNTRY_INCOME_LEVEL = \"LMIC\"  # Low-Middle Income Country (Nigeria)\n",
        "DATASET_SOURCE = \"https://www.kaggle.com/datasets/aminumusa/nigeria-chest-x-ray-dataset\"\n",
        "NUM_CLASSES = 3  # Normal, Pneumonia, TB (dropping COVID-19)\n",
        "\n",
        "print(f\"Dataset: {DATASET_NAME}\")\n",
        "print(f\"Income Level: {COUNTRY_INCOME_LEVEL}\")\n",
        "print(f\"Classes: Normal, Pneumonia, Tuberculosis (COVID-19 dropped)\")\n",
        "\n",
        "# STEP 2: MOUNT DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create results directory\n",
        "!mkdir -p /content/drive/MyDrive/xray_research_results\n",
        "\n",
        "# STEP 3: IMPORT DATASET\n",
        "import kagglehub\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import time\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import shutil\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download dataset\n",
        "print(\"Downloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"aminumusa/nigeria-chest-x-ray-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Explore dataset structure\n",
        "print(\"\\nDataset structure:\")\n",
        "for root, dirs, files in os.walk(path):\n",
        "    level = root.replace(path, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:5]:  # Show first 5 files only\n",
        "        print(f\"{subindent}{file}\")\n",
        "    if len(files) > 5:\n",
        "        print(f\"{subindent}... and {len(files)-5} more files\")\n",
        "\n",
        "# STEP 4: ORGANIZE DATA INTO TRAIN/VAL/TEST SPLITS\n",
        "# Dataset has train_folder and test_folder with 4 classes each\n",
        "# We need to combine them, drop COVID-19, and create new 70/15/15 splits\n",
        "\n",
        "print(\"\\nOrganizing data into train/val/test splits...\")\n",
        "print(\"NOTE: Dropping all COVID-19 images as per project requirements\")\n",
        "\n",
        "# Create organized directory structure\n",
        "base_dir = '/content/organized_data'\n",
        "for split in ['train', 'val', 'test']:\n",
        "    for class_name in ['Normal', 'Pneumonia', 'TB']:\n",
        "        os.makedirs(os.path.join(base_dir, split, class_name), exist_ok=True)\n",
        "\n",
        "# Function to organize dataset\n",
        "def organize_dataset(source_path, base_dir, train_ratio=0.70, val_ratio=0.15, test_ratio=0.15):\n",
        "    \"\"\"\n",
        "    Organize Nigeria dataset into train/val/test splits\n",
        "    Drop COVID-19 class, keep Normal, Pneumonia, TB\n",
        "    \"\"\"\n",
        "    # Collect images by class\n",
        "    class_images = {\n",
        "        'Normal': [],\n",
        "        'Pneumonia': [],\n",
        "        'TB': []\n",
        "    }\n",
        "\n",
        "    covid_count = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(source_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                file_path = os.path.join(root, file)\n",
        "                parent_folder = os.path.basename(root).lower()\n",
        "\n",
        "                # Classify based on folder name\n",
        "                if 'normal' in parent_folder:\n",
        "                    class_images['Normal'].append(file_path)\n",
        "                elif 'pneumonia' in parent_folder:\n",
        "                    class_images['Pneumonia'].append(file_path)\n",
        "                elif 'tb' in parent_folder or 'tuberculosis' in parent_folder:\n",
        "                    class_images['TB'].append(file_path)\n",
        "                elif 'covid' in parent_folder:\n",
        "                    covid_count += 1\n",
        "                    # Skip COVID-19 images\n",
        "                    continue\n",
        "\n",
        "    print(f\"\\nFound images:\")\n",
        "    print(f\"  Normal: {len(class_images['Normal'])}\")\n",
        "    print(f\"  Pneumonia: {len(class_images['Pneumonia'])}\")\n",
        "    print(f\"  TB: {len(class_images['TB'])}\")\n",
        "    print(f\"  COVID-19 (dropped): {covid_count}\")\n",
        "\n",
        "    # Split each class\n",
        "    for class_name, images in class_images.items():\n",
        "        if len(images) == 0:\n",
        "            print(f\"WARNING: No images found for class {class_name}\")\n",
        "            continue\n",
        "\n",
        "        # Shuffle\n",
        "        np.random.seed(42)\n",
        "        np.random.shuffle(images)\n",
        "\n",
        "        # Calculate split indices\n",
        "        n = len(images)\n",
        "        train_end = int(n * train_ratio)\n",
        "        val_end = train_end + int(n * val_ratio)\n",
        "\n",
        "        # Split data\n",
        "        train_files = images[:train_end]\n",
        "        val_files = images[train_end:val_end]\n",
        "        test_files = images[val_end:]\n",
        "\n",
        "        print(f\"\\n{class_name} split: Train={len(train_files)}, Val={len(val_files)}, Test={len(test_files)}\")\n",
        "\n",
        "        # Copy files\n",
        "        for files, split in [(train_files, 'train'), (val_files, 'val'), (test_files, 'test')]:\n",
        "            dest_dir = os.path.join(base_dir, split, class_name)\n",
        "            for i, src in enumerate(files):\n",
        "                dest = os.path.join(dest_dir, f\"{class_name}_{split}_{i}{os.path.splitext(src)[1]}\")\n",
        "                shutil.copy2(src, dest)\n",
        "\n",
        "# Organize the dataset\n",
        "organize_dataset(path, base_dir)\n",
        "\n",
        "# STEP 5: SETUP DATA PREPROCESSING\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "CLASS_NAMES = ['Normal', 'Pneumonia', 'TB']\n",
        "CLASS_MAPPING = {\n",
        "    'Normal': 0,      # Healthy\n",
        "    'Pneumonia': 1,   # Pneumonia\n",
        "    'TB': 2           # Tuberculosis\n",
        "}\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    brightness_range=[0.9, 1.1],\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "# No augmentation for validation and test\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Setup data paths\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "# Check if directories exist\n",
        "print(\"\\nChecking directories:\")\n",
        "print(f\"Train dir exists: {os.path.exists(train_dir)}\")\n",
        "print(f\"Val dir exists: {os.path.exists(val_dir)}\")\n",
        "print(f\"Test dir exists: {os.path.exists(test_dir)}\")\n",
        "\n",
        "# Create data generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Print dataset info\n",
        "print(f\"\\nTraining samples: {train_generator.samples}\")\n",
        "print(f\"Validation samples: {validation_generator.samples}\")\n",
        "print(f\"Test samples: {test_generator.samples}\")\n",
        "print(f\"Classes found: {train_generator.class_indices}\")\n",
        "\n",
        "# STEP 6: DEFINE MODEL ARCHITECTURES\n",
        "\n",
        "def create_baseline_cnn(input_shape=(224, 224, 3), num_classes=3):\n",
        "    \"\"\"Simple CNN baseline\"\"\"\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1 if num_classes == 2 else num_classes,\n",
        "                    activation='sigmoid' if num_classes == 2 else 'softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def create_transfer_model(base_model_name, input_shape=(224, 224, 3), num_classes=3):\n",
        "    \"\"\"Create transfer learning model\"\"\"\n",
        "    # Load base model\n",
        "    if base_model_name == 'MobileNetV2':\n",
        "        base = tf.keras.applications.MobileNetV2(\n",
        "            input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    elif base_model_name == 'EfficientNetB0':\n",
        "        base = tf.keras.applications.EfficientNetB0(\n",
        "            input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    elif base_model_name == 'ResNet50':\n",
        "        base = tf.keras.applications.ResNet50(\n",
        "            input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    elif base_model_name == 'Xception':\n",
        "        base = tf.keras.applications.Xception(\n",
        "            input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    elif base_model_name == 'InceptionV3':\n",
        "        base = tf.keras.applications.InceptionV3(\n",
        "            input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model: {base_model_name}\")\n",
        "\n",
        "    # Freeze base layers\n",
        "    base.trainable = False\n",
        "\n",
        "    # Add custom head\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = base(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1 if num_classes == 2 else num_classes,\n",
        "                          activation='sigmoid' if num_classes == 2 else 'softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# STEP 7: TRAINING AND EVALUATION FUNCTION\n",
        "\n",
        "def train_and_evaluate(model, model_name, train_gen, val_gen, test_gen):\n",
        "    \"\"\"Train model and return results\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {model_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # Compile\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy' if NUM_CLASSES == 2 else 'categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=5, restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "    training_time = (time.time() - start_time) / 60  # in minutes\n",
        "\n",
        "    # Evaluate on test set\n",
        "    print(\"\\nEvaluating on test set...\")\n",
        "    test_loss, test_acc = model.evaluate(test_gen, verbose=0)\n",
        "\n",
        "    # Get predictions\n",
        "    predictions = model.predict(test_gen)\n",
        "    if NUM_CLASSES == 2:\n",
        "        y_pred = (predictions > 0.5).astype(int).flatten()\n",
        "        y_true = test_gen.classes\n",
        "    else:\n",
        "        y_pred = np.argmax(predictions, axis=1)\n",
        "        y_true = test_gen.classes\n",
        "\n",
        "    # Calculate metrics\n",
        "    if NUM_CLASSES == 2:\n",
        "        # Binary classification\n",
        "        f1_per_class = [\n",
        "            f1_score(y_true == 0, y_pred == 0),\n",
        "            f1_score(y_true == 1, y_pred == 1)\n",
        "        ]\n",
        "        f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    else:\n",
        "        # Multi-class\n",
        "        f1_per_class = f1_score(y_true, y_pred, average=None).tolist()\n",
        "        f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Prepare results\n",
        "    results = {\n",
        "        'dataset_name': DATASET_NAME,\n",
        "        'country_income': COUNTRY_INCOME_LEVEL,\n",
        "        'model_name': model_name,\n",
        "        'num_classes': NUM_CLASSES,\n",
        "        'class_names': CLASS_NAMES,\n",
        "        'f1_per_class': f1_per_class,\n",
        "        'f1_weighted': float(f1_weighted),\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'training_time_minutes': float(training_time),\n",
        "        'num_images_train': train_gen.samples,\n",
        "        'num_images_val': val_gen.samples,\n",
        "        'num_images_test': test_gen.samples,\n",
        "        'num_parameters': int(model.count_params()),\n",
        "        'test_accuracy': float(test_acc),\n",
        "        'epochs_trained': len(history.history['loss'])\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"F1 Scores per class: {f1_per_class}\")\n",
        "    print(f\"Weighted F1 Score: {f1_weighted:.4f}\")\n",
        "    print(f\"Training time: {training_time:.2f} minutes\")\n",
        "    print(f\"Parameters: {model.count_params():,}\")\n",
        "\n",
        "    # Save results\n",
        "    filename = f'/content/drive/MyDrive/xray_research_results/{DATASET_NAME}_{COUNTRY_INCOME_LEVEL}_{model_name}_results.json'\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"Results saved to: {filename}\")\n",
        "\n",
        "    # Clear memory\n",
        "    del model\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    return results\n",
        "\n",
        "# STEP 8: TRAIN ALL MODELS\n",
        "\n",
        "all_results = []\n",
        "\n",
        "# Model 1: Baseline CNN\n",
        "model = create_baseline_cnn(num_classes=NUM_CLASSES)\n",
        "results = train_and_evaluate(model, 'BaselineCNN', train_generator, validation_generator, test_generator)\n",
        "all_results.append(results)\n",
        "\n",
        "# Model 2: MobileNetV2\n",
        "model = create_transfer_model('MobileNetV2', num_classes=NUM_CLASSES)\n",
        "results = train_and_evaluate(model, 'MobileNetV2', train_generator, validation_generator, test_generator)\n",
        "all_results.append(results)\n",
        "\n",
        "# Model 3: EfficientNetB0\n",
        "model = create_transfer_model('EfficientNetB0', num_classes=NUM_CLASSES)\n",
        "results = train_and_evaluate(model, 'EfficientNetB0', train_generator, validation_generator, test_generator)\n",
        "all_results.append(results)\n",
        "\n",
        "# Model 4: ResNet50\n",
        "model = create_transfer_model('ResNet50', num_classes=NUM_CLASSES)\n",
        "results = train_and_evaluate(model, 'ResNet50', train_generator, validation_generator, test_generator)\n",
        "all_results.append(results)\n",
        "\n",
        "# STEP 9: SUMMARY\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETE - SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for result in all_results:\n",
        "    print(f\"\\n{result['model_name']}:\")\n",
        "    print(f\"  Weighted F1: {result['f1_weighted']:.4f}\")\n",
        "    print(f\"  Training Time: {result['training_time_minutes']:.2f} min\")\n",
        "    print(f\"  Parameters: {result['num_parameters']:,}\")\n",
        "\n",
        "print(f\"\\nAll results saved to: /content/drive/MyDrive/xray_research_results/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# TRAIN RESNET50 ONLY FOR DATASET 3\n",
        "# NIGERIA CHEST X-RAY DATABASE - FULL SETUP\n",
        "# ==========================================\n",
        "\n",
        "# STEP 1: METADATA\n",
        "DATASET_NAME = \"dataset3_nigeria_chest_xray\"\n",
        "COUNTRY_INCOME_LEVEL = \"LMIC\"\n",
        "NUM_CLASSES = 3\n",
        "CLASS_NAMES = ['Normal', 'Pneumonia', 'TB']\n",
        "\n",
        "print(f\"Training ResNet50 for {DATASET_NAME}\")\n",
        "\n",
        "# STEP 2: MOUNT DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# STEP 3: IMPORTS\n",
        "import kagglehub\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import json\n",
        "import time\n",
        "import gc\n",
        "import shutil\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# STEP 4: DOWNLOAD DATASET\n",
        "print(\"\\nDownloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"aminumusa/nigeria-chest-x-ray-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# STEP 5: ORGANIZE DATA\n",
        "print(\"\\nOrganizing data into train/val/test splits...\")\n",
        "print(\"NOTE: Dropping all COVID-19 images as per project requirements\")\n",
        "\n",
        "base_dir = '/content/organized_data'\n",
        "for split in ['train', 'val', 'test']:\n",
        "    for class_name in ['Normal', 'Pneumonia', 'TB']:\n",
        "        os.makedirs(os.path.join(base_dir, split, class_name), exist_ok=True)\n",
        "\n",
        "def organize_dataset(source_path, base_dir, train_ratio=0.70, val_ratio=0.15, test_ratio=0.15):\n",
        "    \"\"\"Organize Nigeria dataset into train/val/test splits\"\"\"\n",
        "    class_images = {\n",
        "        'Normal': [],\n",
        "        'Pneumonia': [],\n",
        "        'TB': []\n",
        "    }\n",
        "\n",
        "    covid_count = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(source_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                file_path = os.path.join(root, file)\n",
        "                parent_folder = os.path.basename(root).lower()\n",
        "\n",
        "                if 'normal' in parent_folder:\n",
        "                    class_images['Normal'].append(file_path)\n",
        "                elif 'pneumonia' in parent_folder:\n",
        "                    class_images['Pneumonia'].append(file_path)\n",
        "                elif 'tb' in parent_folder or 'tuberculosis' in parent_folder:\n",
        "                    class_images['TB'].append(file_path)\n",
        "                elif 'covid' in parent_folder:\n",
        "                    covid_count += 1\n",
        "                    continue\n",
        "\n",
        "    print(f\"\\nFound images:\")\n",
        "    print(f\"  Normal: {len(class_images['Normal'])}\")\n",
        "    print(f\"  Pneumonia: {len(class_images['Pneumonia'])}\")\n",
        "    print(f\"  TB: {len(class_images['TB'])}\")\n",
        "    print(f\"  COVID-19 (dropped): {covid_count}\")\n",
        "\n",
        "    for class_name, images in class_images.items():\n",
        "        if len(images) == 0:\n",
        "            print(f\"WARNING: No images found for class {class_name}\")\n",
        "            continue\n",
        "\n",
        "        np.random.seed(42)\n",
        "        np.random.shuffle(images)\n",
        "\n",
        "        n = len(images)\n",
        "        train_end = int(n * train_ratio)\n",
        "        val_end = train_end + int(n * val_ratio)\n",
        "\n",
        "        train_files = images[:train_end]\n",
        "        val_files = images[train_end:val_end]\n",
        "        test_files = images[val_end:]\n",
        "\n",
        "        print(f\"\\n{class_name} split: Train={len(train_files)}, Val={len(val_files)}, Test={len(test_files)}\")\n",
        "\n",
        "        for files, split in [(train_files, 'train'), (val_files, 'val'), (test_files, 'test')]:\n",
        "            dest_dir = os.path.join(base_dir, split, class_name)\n",
        "            for i, src in enumerate(files):\n",
        "                dest = os.path.join(dest_dir, f\"{class_name}_{split}_{i}{os.path.splitext(src)[1]}\")\n",
        "                shutil.copy2(src, dest)\n",
        "\n",
        "organize_dataset(path, base_dir)\n",
        "\n",
        "# STEP 6: SETUP DATA PREPROCESSING\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    brightness_range=[0.9, 1.1],\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"\\nData loaded:\")\n",
        "print(f\"Training samples: {train_generator.samples}\")\n",
        "print(f\"Validation samples: {validation_generator.samples}\")\n",
        "print(f\"Test samples: {test_generator.samples}\")\n",
        "print(f\"Classes found: {train_generator.class_indices}\")\n",
        "\n",
        "# STEP 7: COMPUTE CLASS WEIGHTS\n",
        "y_train = train_generator.classes\n",
        "class_weights_array = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
        "\n",
        "print(f\"\\nClass distribution in training:\")\n",
        "for i, class_name in enumerate(CLASS_NAMES):\n",
        "    print(f\"  {class_name} ({i}): {np.sum(y_train == i)} samples\")\n",
        "print(f\"Class weights computed: {class_weights}\")\n",
        "\n",
        "# STEP 8: CREATE MODEL\n",
        "def create_resnet50(input_shape=(224, 224, 3), num_classes=3):\n",
        "    \"\"\"Create ResNet50 transfer learning model\"\"\"\n",
        "    base = tf.keras.applications.ResNet50(\n",
        "        input_shape=input_shape,\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "\n",
        "    base.trainable = False\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = base(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# STEP 9: TRAIN AND EVALUATE\n",
        "def train_and_evaluate(model, model_name, train_gen, val_gen, test_gen, class_weights):\n",
        "    \"\"\"Train model and return results\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {model_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=[early_stop, reduce_lr],\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "    training_time = (time.time() - start_time) / 60\n",
        "\n",
        "    print(\"\\nEvaluating on test set...\")\n",
        "    test_loss, test_acc = model.evaluate(test_gen, verbose=0)\n",
        "\n",
        "    predictions = model.predict(test_gen)\n",
        "    y_pred = np.argmax(predictions, axis=1)\n",
        "    y_true = test_gen.classes\n",
        "\n",
        "    f1_per_class = f1_score(y_true, y_pred, average=None).tolist()\n",
        "    f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    results = {\n",
        "        'dataset_name': DATASET_NAME,\n",
        "        'country_income': COUNTRY_INCOME_LEVEL,\n",
        "        'model_name': model_name,\n",
        "        'num_classes': NUM_CLASSES,\n",
        "        'class_names': CLASS_NAMES,\n",
        "        'f1_per_class': f1_per_class,\n",
        "        'f1_weighted': float(f1_weighted),\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'training_time_minutes': float(training_time),\n",
        "        'num_images_train': train_gen.samples,\n",
        "        'num_images_val': val_gen.samples,\n",
        "        'num_images_test': test_gen.samples,\n",
        "        'num_parameters': int(model.count_params()),\n",
        "        'test_accuracy': float(test_acc),\n",
        "        'epochs_trained': len(history.history['loss'])\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"F1 Scores per class: {f1_per_class}\")\n",
        "    print(f\"Weighted F1 Score: {f1_weighted:.4f}\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "    print(f\"Training time: {training_time:.2f} minutes\")\n",
        "    print(f\"Parameters: {model.count_params():,}\")\n",
        "\n",
        "    filename = f'/content/drive/MyDrive/xray_research_results/{DATASET_NAME}_{COUNTRY_INCOME_LEVEL}_{model_name}_results.json'\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"Results saved to: {filename}\")\n",
        "\n",
        "    del model\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    return results\n",
        "\n",
        "# STEP 10: TRAIN RESNET50\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING RESNET50 TRAINING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model = create_resnet50(num_classes=NUM_CLASSES)\n",
        "results = train_and_evaluate(\n",
        "    model,\n",
        "    'ResNet50',\n",
        "    train_generator,\n",
        "    validation_generator,\n",
        "    test_generator,\n",
        "    class_weights\n",
        ")\n",
        "\n",
        "# STEP 11: SUMMARY\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nResNet50:\")\n",
        "print(f\"  Weighted F1: {results['f1_weighted']:.4f}\")\n",
        "print(f\"  F1 per class: {results['f1_per_class']}\")\n",
        "print(f\"  Training Time: {results['training_time_minutes']:.2f} min\")\n",
        "print(f\"  Parameters: {results['num_parameters']:,}\")\n",
        "print(f\"\\nResults saved to: /content/drive/MyDrive/xray_research_results/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZSI_rq-jerL",
        "outputId": "5fe717ea-98b4-4098-89e7-d49802d5409b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ResNet50 for dataset3_nigeria_chest_xray\n",
            "Mounted at /content/drive\n",
            "\n",
            "Downloading dataset...\n",
            "Using Colab cache for faster access to the 'nigeria-chest-x-ray-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/nigeria-chest-x-ray-dataset\n",
            "\n",
            "Organizing data into train/val/test splits...\n",
            "NOTE: Dropping all COVID-19 images as per project requirements\n",
            "\n",
            "Found images:\n",
            "  Normal: 650\n",
            "  Pneumonia: 650\n",
            "  TB: 650\n",
            "  COVID-19 (dropped): 650\n",
            "\n",
            "Normal split: Train=454, Val=97, Test=99\n",
            "\n",
            "Pneumonia split: Train=454, Val=97, Test=99\n",
            "\n",
            "TB split: Train=454, Val=97, Test=99\n",
            "Found 1362 images belonging to 3 classes.\n",
            "Found 291 images belonging to 3 classes.\n",
            "Found 297 images belonging to 3 classes.\n",
            "\n",
            "Data loaded:\n",
            "Training samples: 1362\n",
            "Validation samples: 291\n",
            "Test samples: 297\n",
            "Classes found: {'Normal': 0, 'Pneumonia': 1, 'TB': 2}\n",
            "\n",
            "Class distribution in training:\n",
            "  Normal (0): 454 samples\n",
            "  Pneumonia (1): 454 samples\n",
            "  TB (2): 454 samples\n",
            "Class weights computed: {0: np.float64(1.0), 1: np.float64(1.0), 2: np.float64(1.0)}\n",
            "\n",
            "============================================================\n",
            "STARTING RESNET50 TRAINING\n",
            "============================================================\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "==================================================\n",
            "Training ResNet50\n",
            "==================================================\n",
            "Epoch 1/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m340s\u001b[0m 8s/step - accuracy: 0.3503 - loss: 1.3267 - val_accuracy: 0.3368 - val_loss: 1.0947 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 7s/step - accuracy: 0.3143 - loss: 1.1030 - val_accuracy: 0.5155 - val_loss: 1.0911 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 7s/step - accuracy: 0.3535 - loss: 1.0997 - val_accuracy: 0.3471 - val_loss: 1.0928 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 7s/step - accuracy: 0.3099 - loss: 1.1008 - val_accuracy: 0.3333 - val_loss: 1.0945 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3358 - loss: 1.0976\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 7s/step - accuracy: 0.3357 - loss: 1.0976 - val_accuracy: 0.3436 - val_loss: 1.0952 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 7s/step - accuracy: 0.3821 - loss: 1.0956 - val_accuracy: 0.3436 - val_loss: 1.0946 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 7s/step - accuracy: 0.3368 - loss: 1.0976 - val_accuracy: 0.4880 - val_loss: 1.0940 - learning_rate: 5.0000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\n",
            "Evaluating on test set...\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 5s/step\n",
            "\n",
            "ResNet50 Results:\n",
            "F1 Scores per class: [0.3013698630136986, 0.6508474576271186, 0.5228758169934641]\n",
            "Weighted F1 Score: 0.4917\n",
            "Confusion Matrix:\n",
            "[[22 65 12]\n",
            " [ 1 96  2]\n",
            " [24 35 40]]\n",
            "Training time: 35.41 minutes\n",
            "Parameters: 23,850,371\n",
            "Results saved to: /content/drive/MyDrive/xray_research_results/dataset3_nigeria_chest_xray_LMIC_ResNet50_results.json\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETE\n",
            "============================================================\n",
            "\n",
            "ResNet50:\n",
            "  Weighted F1: 0.4917\n",
            "  F1 per class: [0.3013698630136986, 0.6508474576271186, 0.5228758169934641]\n",
            "  Training Time: 35.41 min\n",
            "  Parameters: 23,850,371\n",
            "\n",
            "Results saved to: /content/drive/MyDrive/xray_research_results/\n"
          ]
        }
      ]
    }
  ]
}