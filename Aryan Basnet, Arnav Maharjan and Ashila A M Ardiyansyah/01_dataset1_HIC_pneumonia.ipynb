{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10710arnav/Noesis/blob/main/Aryan%20Basnet%2C%20Arnav%20Maharjan%20and%20Ashila%20A%20M%20Ardiyansyah/01_dataset1_HIC_pneumonia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NOTE ON RUNTIME AND OUTPUTS**\n",
        "\n",
        "# Google Colab may have disconnected or reset the runtime during long training sessions, crashes, or memory interruptions. When this occurred, some previously displayed outputs in the notebook were no longer visible. However, all results remained saved and logged correctly. Each model’s complete metrics and metadata were stored as JSON files in my Google Drive folder:\n",
        "\n",
        "# [https://drive.google.com/drive/folders/1ejlJaZhHEBm-1khLBJ--mbG2pg5TZHoJ?usp=sharing](https://drive.google.com/drive/folders/1ejlJaZhHEBm-1khLBJ--mbG2pg5TZHoJ?usp=sharing)\n",
        "\n",
        "# These JSON files contain the full and reliable outputs for all models across all datasets, even if certain notebook outputs were lost due to runtime resets."
      ],
      "metadata": {
        "id": "5cIgbdH1Xq3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ==============================\n",
        "# SETUP: Freeze all package versions\n",
        "# ==============================\n",
        "Ensure reproducibility by installing the exact versions of packages used in these notebooks. This includes pre-installed packages in Colab.\n",
        "\n",
        "The packages and versions used are:\n",
        "\n",
        "- numpy==1.25.2\n",
        "- pandas==2.1.1\n",
        "- matplotlib==3.8.0\n",
        "- seaborn==0.12.2\n",
        "- scikit-learn==1.3.2\n",
        "- tensorflow==2.15.0\n",
        "- keras==2.15.0\n",
        "- scipy==1.11.2\n",
        "- opencv-python==4.9.0.73\n",
        "- Pillow==10.0.1\n",
        "- h5py==3.9.0\n",
        "- google-colab==2.0.0"
      ],
      "metadata": {
        "id": "FQ6_Sfsf8L92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bck2kRAe0KSi",
        "outputId": "dc608a85-b9ce-4eaf-8d5e-2ffbb9cd501d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: dataset1_chest_xray_pneumonia\n",
            "Income Level: HIC\n",
            "Classes: Healthy, Pneumonia (No TB in this dataset)\n",
            "Mounted at /content/drive\n",
            "Downloading dataset...\n",
            "Using Colab cache for faster access to the 'chest-xray-pneumonia' dataset.\n",
            "Path to dataset files: /kaggle/input/chest-xray-pneumonia\n",
            "\n",
            "Dataset structure:\n",
            "chest-xray-pneumonia/\n",
            "  chest_xray/\n",
            "    chest_xray/\n",
            "      .DS_Store\n",
            "      val/\n",
            "        .DS_Store\n",
            "        PNEUMONIA/\n",
            "          person1947_bacteria_4876.jpeg\n",
            "          person1946_bacteria_4875.jpeg\n",
            "          person1952_bacteria_4883.jpeg\n",
            "          person1954_bacteria_4886.jpeg\n",
            "          person1951_bacteria_4882.jpeg\n",
            "          ... and 4 more files\n",
            "        NORMAL/\n",
            "          NORMAL2-IM-1431-0001.jpeg\n",
            "          NORMAL2-IM-1440-0001.jpeg\n",
            "          NORMAL2-IM-1442-0001.jpeg\n",
            "          NORMAL2-IM-1427-0001.jpeg\n",
            "          NORMAL2-IM-1430-0001.jpeg\n",
            "          ... and 4 more files\n",
            "      test/\n",
            "        .DS_Store\n",
            "        PNEUMONIA/\n",
            "          person1676_virus_2892.jpeg\n",
            "          person1650_virus_2852.jpeg\n",
            "          person22_virus_55.jpeg\n",
            "          person122_bacteria_582.jpeg\n",
            "          person85_bacteria_417.jpeg\n",
            "          ... and 385 more files\n",
            "        NORMAL/\n",
            "          NORMAL2-IM-0336-0001.jpeg\n",
            "          IM-0101-0001.jpeg\n",
            "          NORMAL2-IM-0337-0001.jpeg\n",
            "          NORMAL2-IM-0198-0001.jpeg\n",
            "          IM-0013-0001.jpeg\n",
            "          ... and 229 more files\n",
            "      train/\n",
            "        .DS_Store\n",
            "        PNEUMONIA/\n",
            "          person1180_virus_2010.jpeg\n",
            "          person1230_virus_2081.jpeg\n",
            "          person1513_virus_2632.jpeg\n",
            "          person124_virus_238.jpeg\n",
            "          person746_virus_1369.jpeg\n",
            "          ... and 3871 more files\n",
            "        NORMAL/\n",
            "          NORMAL2-IM-0771-0001.jpeg\n",
            "          NORMAL2-IM-1294-0001-0002.jpeg\n",
            "          IM-0675-0001.jpeg\n",
            "          NORMAL2-IM-1169-0001.jpeg\n",
            "          IM-0421-0001.jpeg\n",
            "          ... and 1337 more files\n",
            "    __MACOSX/\n",
            "      ._chest_xray\n",
            "      chest_xray/\n",
            "        ._.DS_Store\n",
            "        ._train\n",
            "        ._test\n",
            "        val/\n",
            "          ._.DS_Store\n",
            "          PNEUMONIA/\n",
            "            ._person1946_bacteria_4875.jpeg\n",
            "            ._person1952_bacteria_4883.jpeg\n",
            "            ._person1949_bacteria_4880.jpeg\n",
            "            ._.DS_Store\n",
            "            ._person1950_bacteria_4881.jpeg\n",
            "            ... and 4 more files\n",
            "          NORMAL/\n",
            "            ._NORMAL2-IM-1442-0001.jpeg\n",
            "            ._NORMAL2-IM-1436-0001.jpeg\n",
            "            ._NORMAL2-IM-1430-0001.jpeg\n",
            "            ._.DS_Store\n",
            "            ._NORMAL2-IM-1431-0001.jpeg\n",
            "            ... and 4 more files\n",
            "        test/\n",
            "          ._PNEUMONIA\n",
            "          ._NORMAL\n",
            "          ._.DS_Store\n",
            "          PNEUMONIA/\n",
            "            ._person8_virus_28.jpeg\n",
            "            ._person122_bacteria_585.jpeg\n",
            "            ._person154_bacteria_728.jpeg\n",
            "            ._person1650_virus_2854.jpeg\n",
            "            ._person112_bacteria_538.jpeg\n",
            "            ... and 385 more files\n",
            "          NORMAL/\n",
            "            ._IM-0036-0001.jpeg\n",
            "            ._NORMAL2-IM-0348-0001.jpeg\n",
            "            ._IM-0086-0001.jpeg\n",
            "            ._NORMAL2-IM-0259-0001.jpeg\n",
            "            ._NORMAL2-IM-0051-0001.jpeg\n",
            "            ... and 229 more files\n",
            "        train/\n",
            "          ._PNEUMONIA\n",
            "          ._NORMAL\n",
            "          ._.DS_Store\n",
            "          PNEUMONIA/\n",
            "            ._person499_bacteria_2104.jpeg\n",
            "            ._person515_bacteria_2190.jpeg\n",
            "            ._person426_virus_873.jpeg\n",
            "            ._person1171_bacteria_3118.jpeg\n",
            "            ._person1119_virus_1844.jpeg\n",
            "            ... and 3871 more files\n",
            "          NORMAL/\n",
            "            ._IM-0473-0001.jpeg\n",
            "            ._NORMAL2-IM-0416-0001.jpeg\n",
            "            ._IM-0696-0001.jpeg\n",
            "            ._NORMAL2-IM-1419-0001.jpeg\n",
            "            ._IM-0343-0001.jpeg\n",
            "            ... and 1337 more files\n",
            "    val/\n",
            "      PNEUMONIA/\n",
            "        person1947_bacteria_4876.jpeg\n",
            "        person1946_bacteria_4875.jpeg\n",
            "        person1952_bacteria_4883.jpeg\n",
            "        person1954_bacteria_4886.jpeg\n",
            "        person1951_bacteria_4882.jpeg\n",
            "        ... and 3 more files\n",
            "      NORMAL/\n",
            "        NORMAL2-IM-1431-0001.jpeg\n",
            "        NORMAL2-IM-1440-0001.jpeg\n",
            "        NORMAL2-IM-1442-0001.jpeg\n",
            "        NORMAL2-IM-1427-0001.jpeg\n",
            "        NORMAL2-IM-1430-0001.jpeg\n",
            "        ... and 3 more files\n",
            "    test/\n",
            "      PNEUMONIA/\n",
            "        person1676_virus_2892.jpeg\n",
            "        person1650_virus_2852.jpeg\n",
            "        person22_virus_55.jpeg\n",
            "        person122_bacteria_582.jpeg\n",
            "        person85_bacteria_417.jpeg\n",
            "        ... and 385 more files\n",
            "      NORMAL/\n",
            "        NORMAL2-IM-0336-0001.jpeg\n",
            "        IM-0101-0001.jpeg\n",
            "        NORMAL2-IM-0337-0001.jpeg\n",
            "        NORMAL2-IM-0198-0001.jpeg\n",
            "        IM-0013-0001.jpeg\n",
            "        ... and 229 more files\n",
            "    train/\n",
            "      PNEUMONIA/\n",
            "        person1180_virus_2010.jpeg\n",
            "        person1230_virus_2081.jpeg\n",
            "        person1513_virus_2632.jpeg\n",
            "        person124_virus_238.jpeg\n",
            "        person746_virus_1369.jpeg\n",
            "        ... and 3870 more files\n",
            "      NORMAL/\n",
            "        NORMAL2-IM-0771-0001.jpeg\n",
            "        NORMAL2-IM-1294-0001-0002.jpeg\n",
            "        IM-0675-0001.jpeg\n",
            "        NORMAL2-IM-1169-0001.jpeg\n",
            "        IM-0421-0001.jpeg\n",
            "        ... and 1336 more files\n",
            "\n",
            "Checking directories:\n",
            "Train dir exists: True\n",
            "Test dir exists: True\n",
            "Val dir exists: True\n",
            "Found 4434 images belonging to 2 classes.\n",
            "Found 782 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n",
            "\n",
            "Training samples: 4434\n",
            "Validation samples: 782\n",
            "Test samples: 624\n",
            "Classes found: {'NORMAL': 0, 'PNEUMONIA': 1}\n",
            "\n",
            "==================================================\n",
            "Training BaselineCNN\n",
            "==================================================\n",
            "Epoch 1/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 1s/step - accuracy: 0.7488 - loss: 0.6918 - val_accuracy: 0.8683 - val_loss: 0.2901\n",
            "Epoch 2/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 875ms/step - accuracy: 0.8666 - loss: 0.3096 - val_accuracy: 0.8836 - val_loss: 0.2613\n",
            "Epoch 3/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 842ms/step - accuracy: 0.9185 - loss: 0.2253 - val_accuracy: 0.8951 - val_loss: 0.2755\n",
            "Epoch 4/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 864ms/step - accuracy: 0.9188 - loss: 0.1900 - val_accuracy: 0.8939 - val_loss: 0.2577\n",
            "Epoch 5/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 854ms/step - accuracy: 0.9218 - loss: 0.2089 - val_accuracy: 0.8990 - val_loss: 0.2241\n",
            "Epoch 6/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 836ms/step - accuracy: 0.9343 - loss: 0.1819 - val_accuracy: 0.9169 - val_loss: 0.2066\n",
            "Epoch 7/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 854ms/step - accuracy: 0.9390 - loss: 0.1787 - val_accuracy: 0.8798 - val_loss: 0.2497\n",
            "Epoch 8/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 847ms/step - accuracy: 0.9438 - loss: 0.1711 - val_accuracy: 0.9309 - val_loss: 0.1442\n",
            "Epoch 9/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 869ms/step - accuracy: 0.9498 - loss: 0.1487 - val_accuracy: 0.9335 - val_loss: 0.1561\n",
            "Epoch 10/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 872ms/step - accuracy: 0.9458 - loss: 0.1480 - val_accuracy: 0.9425 - val_loss: 0.1412\n",
            "Epoch 11/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 862ms/step - accuracy: 0.9609 - loss: 0.1351 - val_accuracy: 0.9437 - val_loss: 0.1474\n",
            "Epoch 12/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 853ms/step - accuracy: 0.9507 - loss: 0.1352 - val_accuracy: 0.9450 - val_loss: 0.1385\n",
            "Epoch 13/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 855ms/step - accuracy: 0.9564 - loss: 0.1384 - val_accuracy: 0.9437 - val_loss: 0.1585\n",
            "Epoch 14/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 860ms/step - accuracy: 0.9509 - loss: 0.1501 - val_accuracy: 0.9412 - val_loss: 0.1432\n",
            "Epoch 15/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 845ms/step - accuracy: 0.9594 - loss: 0.1226 - val_accuracy: 0.9425 - val_loss: 0.1436\n",
            "Epoch 16/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 846ms/step - accuracy: 0.9569 - loss: 0.1369 - val_accuracy: 0.9233 - val_loss: 0.1743\n",
            "Epoch 17/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 854ms/step - accuracy: 0.9584 - loss: 0.1371 - val_accuracy: 0.9182 - val_loss: 0.1942\n",
            "\n",
            "Evaluating on test set...\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step\n",
            "\n",
            "BaselineCNN Results:\n",
            "F1 Scores per class: [0.6361031518624641, 0.8587319243604005]\n",
            "Weighted F1 Score: 0.7752\n",
            "Training time: 34.36 minutes\n",
            "Parameters: 11,132,033\n",
            "Results saved to: /content/drive/MyDrive/xray_research_results/dataset1_chest_xray_pneumonia_HIC_BaselineCNN_results.json\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "==================================================\n",
            "Training MobileNetV2\n",
            "==================================================\n",
            "Epoch 1/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 1s/step - accuracy: 0.8447 - loss: 0.3730 - val_accuracy: 0.9399 - val_loss: 0.1555\n",
            "Epoch 2/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 844ms/step - accuracy: 0.9446 - loss: 0.1403 - val_accuracy: 0.9565 - val_loss: 0.1225\n",
            "Epoch 3/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 842ms/step - accuracy: 0.9514 - loss: 0.1267 - val_accuracy: 0.9540 - val_loss: 0.1160\n",
            "Epoch 4/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 823ms/step - accuracy: 0.9565 - loss: 0.1051 - val_accuracy: 0.9501 - val_loss: 0.1120\n",
            "Epoch 5/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 857ms/step - accuracy: 0.9623 - loss: 0.0974 - val_accuracy: 0.9501 - val_loss: 0.1158\n",
            "Epoch 6/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 844ms/step - accuracy: 0.9592 - loss: 0.1032 - val_accuracy: 0.9399 - val_loss: 0.1508\n",
            "Epoch 7/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 851ms/step - accuracy: 0.9668 - loss: 0.0936 - val_accuracy: 0.9540 - val_loss: 0.1187\n",
            "Epoch 8/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 862ms/step - accuracy: 0.9578 - loss: 0.1037 - val_accuracy: 0.9629 - val_loss: 0.0927\n",
            "Epoch 9/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 840ms/step - accuracy: 0.9667 - loss: 0.0922 - val_accuracy: 0.9668 - val_loss: 0.0983\n",
            "Epoch 10/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 841ms/step - accuracy: 0.9633 - loss: 0.0929 - val_accuracy: 0.9693 - val_loss: 0.0877\n",
            "Epoch 11/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 844ms/step - accuracy: 0.9666 - loss: 0.0834 - val_accuracy: 0.9501 - val_loss: 0.1077\n",
            "Epoch 12/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 829ms/step - accuracy: 0.9650 - loss: 0.0892 - val_accuracy: 0.9591 - val_loss: 0.1066\n",
            "Epoch 13/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 862ms/step - accuracy: 0.9674 - loss: 0.0916 - val_accuracy: 0.9629 - val_loss: 0.0969\n",
            "Epoch 14/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 843ms/step - accuracy: 0.9694 - loss: 0.0847 - val_accuracy: 0.9693 - val_loss: 0.0764\n",
            "Epoch 15/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 827ms/step - accuracy: 0.9646 - loss: 0.0967 - val_accuracy: 0.9591 - val_loss: 0.1079\n",
            "Epoch 16/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 858ms/step - accuracy: 0.9638 - loss: 0.0937 - val_accuracy: 0.9655 - val_loss: 0.0940\n",
            "Epoch 17/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 842ms/step - accuracy: 0.9733 - loss: 0.0740 - val_accuracy: 0.9540 - val_loss: 0.1034\n",
            "Epoch 18/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 863ms/step - accuracy: 0.9645 - loss: 0.0896 - val_accuracy: 0.9604 - val_loss: 0.0954\n",
            "Epoch 19/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 857ms/step - accuracy: 0.9674 - loss: 0.0905 - val_accuracy: 0.9629 - val_loss: 0.0882\n",
            "\n",
            "Evaluating on test set...\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 442ms/step\n",
            "\n",
            "MobileNetV2 Results:\n",
            "F1 Scores per class: [0.8195121951219512, 0.9116945107398569]\n",
            "Weighted F1 Score: 0.8771\n",
            "Training time: 38.04 minutes\n",
            "Parameters: 2,422,081\n",
            "Results saved to: /content/drive/MyDrive/xray_research_results/dataset1_chest_xray_pneumonia_HIC_MobileNetV2_results.json\n",
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "==================================================\n",
            "Training EfficientNetB0\n",
            "==================================================\n",
            "Epoch 1/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - accuracy: 0.7505 - loss: 0.5833 - val_accuracy: 0.7430 - val_loss: 0.5703\n",
            "Epoch 2/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 865ms/step - accuracy: 0.7290 - loss: 0.5966 - val_accuracy: 0.7430 - val_loss: 0.5699\n",
            "Epoch 3/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 852ms/step - accuracy: 0.7440 - loss: 0.5816 - val_accuracy: 0.7430 - val_loss: 0.5744\n",
            "Epoch 4/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 868ms/step - accuracy: 0.7438 - loss: 0.5826 - val_accuracy: 0.7430 - val_loss: 0.5701\n",
            "Epoch 5/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 851ms/step - accuracy: 0.7309 - loss: 0.5904 - val_accuracy: 0.7430 - val_loss: 0.5698\n",
            "Epoch 6/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 889ms/step - accuracy: 0.7281 - loss: 0.5923 - val_accuracy: 0.7430 - val_loss: 0.5701\n",
            "Epoch 7/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 876ms/step - accuracy: 0.7322 - loss: 0.5909 - val_accuracy: 0.7430 - val_loss: 0.5703\n",
            "Epoch 8/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 842ms/step - accuracy: 0.7499 - loss: 0.5756 - val_accuracy: 0.7430 - val_loss: 0.5700\n",
            "Epoch 9/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 863ms/step - accuracy: 0.7227 - loss: 0.6012 - val_accuracy: 0.7430 - val_loss: 0.5710\n",
            "Epoch 10/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 856ms/step - accuracy: 0.7315 - loss: 0.5893 - val_accuracy: 0.7430 - val_loss: 0.5699\n",
            "\n",
            "Evaluating on test set...\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 589ms/step\n",
            "\n",
            "EfficientNetB0 Results:\n",
            "F1 Scores per class: [0.0, 0.7692307692307693]\n",
            "Weighted F1 Score: 0.4808\n",
            "Training time: 21.00 minutes\n",
            "Parameters: 4,213,668\n",
            "Results saved to: /content/drive/MyDrive/xray_research_results/dataset1_chest_xray_pneumonia_HIC_EfficientNetB0_results.json\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "==================================================\n",
            "Training ResNet50\n",
            "==================================================\n",
            "Epoch 1/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 986ms/step - accuracy: 0.7211 - loss: 0.6118 - val_accuracy: 0.7430 - val_loss: 0.5268\n",
            "Epoch 2/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 863ms/step - accuracy: 0.7462 - loss: 0.5201 - val_accuracy: 0.7660 - val_loss: 0.5102\n",
            "Epoch 3/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 902ms/step - accuracy: 0.7474 - loss: 0.5019 - val_accuracy: 0.7813 - val_loss: 0.4678\n",
            "Epoch 4/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 880ms/step - accuracy: 0.7799 - loss: 0.4585 - val_accuracy: 0.8005 - val_loss: 0.4257\n",
            "Epoch 5/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 883ms/step - accuracy: 0.7947 - loss: 0.4285 - val_accuracy: 0.7903 - val_loss: 0.4102\n",
            "Epoch 6/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 898ms/step - accuracy: 0.7937 - loss: 0.4119 - val_accuracy: 0.7801 - val_loss: 0.4072\n",
            "Epoch 7/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 879ms/step - accuracy: 0.8000 - loss: 0.4212 - val_accuracy: 0.8056 - val_loss: 0.4047\n",
            "Epoch 8/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 869ms/step - accuracy: 0.7874 - loss: 0.4237 - val_accuracy: 0.7967 - val_loss: 0.3843\n",
            "Epoch 9/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 877ms/step - accuracy: 0.7971 - loss: 0.4041 - val_accuracy: 0.7928 - val_loss: 0.4039\n",
            "Epoch 10/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 865ms/step - accuracy: 0.7961 - loss: 0.4017 - val_accuracy: 0.8107 - val_loss: 0.3751\n",
            "Epoch 11/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 891ms/step - accuracy: 0.8133 - loss: 0.3875 - val_accuracy: 0.8171 - val_loss: 0.3619\n",
            "Epoch 12/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 880ms/step - accuracy: 0.8027 - loss: 0.3929 - val_accuracy: 0.7992 - val_loss: 0.3730\n",
            "Epoch 13/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 885ms/step - accuracy: 0.8279 - loss: 0.3800 - val_accuracy: 0.8171 - val_loss: 0.3814\n",
            "Epoch 14/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 904ms/step - accuracy: 0.8177 - loss: 0.3907 - val_accuracy: 0.8120 - val_loss: 0.3587\n",
            "Epoch 15/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 900ms/step - accuracy: 0.8256 - loss: 0.3667 - val_accuracy: 0.8069 - val_loss: 0.3433\n",
            "Epoch 16/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 916ms/step - accuracy: 0.8270 - loss: 0.3582 - val_accuracy: 0.8095 - val_loss: 0.3778\n",
            "Epoch 17/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 898ms/step - accuracy: 0.8243 - loss: 0.3811 - val_accuracy: 0.8184 - val_loss: 0.3753\n",
            "Epoch 18/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 890ms/step - accuracy: 0.8246 - loss: 0.3849 - val_accuracy: 0.8325 - val_loss: 0.3507\n",
            "Epoch 19/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 896ms/step - accuracy: 0.8432 - loss: 0.3483 - val_accuracy: 0.8043 - val_loss: 0.4130\n",
            "Epoch 20/20\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 882ms/step - accuracy: 0.8352 - loss: 0.3669 - val_accuracy: 0.8120 - val_loss: 0.3616\n",
            "\n",
            "Evaluating on test set...\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 505ms/step\n",
            "\n",
            "ResNet50 Results:\n",
            "F1 Scores per class: [0.6020942408376964, 0.8244803695150116]\n",
            "Weighted F1 Score: 0.7411\n",
            "Training time: 41.57 minutes\n",
            "Parameters: 23,850,113\n",
            "Results saved to: /content/drive/MyDrive/xray_research_results/dataset1_chest_xray_pneumonia_HIC_ResNet50_results.json\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETE - SUMMARY\n",
            "============================================================\n",
            "\n",
            "BaselineCNN:\n",
            "  Weighted F1: 0.7752\n",
            "  Training Time: 34.36 min\n",
            "  Parameters: 11,132,033\n",
            "\n",
            "MobileNetV2:\n",
            "  Weighted F1: 0.8771\n",
            "  Training Time: 38.04 min\n",
            "  Parameters: 2,422,081\n",
            "\n",
            "EfficientNetB0:\n",
            "  Weighted F1: 0.4808\n",
            "  Training Time: 21.00 min\n",
            "  Parameters: 4,213,668\n",
            "\n",
            "ResNet50:\n",
            "  Weighted F1: 0.7411\n",
            "  Training Time: 41.57 min\n",
            "  Parameters: 23,850,113\n",
            "\n",
            "All results saved to: /content/drive/MyDrive/xray_research_results/\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# CHEST X-RAY CLASSIFICATION - DATASET 1\n",
        "# ==========================================\n",
        "# stating metadata for tracking dataset identity\n",
        "\n",
        "# STEP 1: METADATA\n",
        "# defining dataset properties and labels\n",
        "DATASET_NAME = \"dataset1_chest_xray_pneumonia\"\n",
        "COUNTRY_INCOME_LEVEL = \"HIC\"  # High Income Country\n",
        "DATASET_SOURCE = \"https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\"\n",
        "NUM_CLASSES = 2  # using two-class setup: Healthy vs Pneumonia\n",
        "\n",
        "# printing dataset info for traceability\n",
        "print(f\"Dataset: {DATASET_NAME}\")\n",
        "print(f\"Income Level: {COUNTRY_INCOME_LEVEL}\")\n",
        "print(f\"Classes: Healthy, Pneumonia (No TB in this dataset)\")\n",
        "\n",
        "# STEP 2: MOUNT DRIVE\n",
        "# mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# creating directory for storing results\n",
        "!mkdir -p /content/drive/MyDrive/xray_research_results\n",
        "\n",
        "# STEP 3: IMPORT DATASET\n",
        "# importing required packages\n",
        "import kagglehub\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "import json\n",
        "import time\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# downloading dataset from Kaggle\n",
        "print(\"Downloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# printing dataset structure for inspection\n",
        "print(\"\\nDataset structure:\")\n",
        "for root, dirs, files in os.walk(path):\n",
        "    level = root.replace(path, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:5]:  # showing first few files only\n",
        "        print(f\"{subindent}{file}\")\n",
        "    if len(files) > 5:\n",
        "        print(f\"{subindent}... and {len(files)-5} more files\")\n",
        "\n",
        "# STEP 4: SETUP DATA PREPROCESSING\n",
        "# defining preprocessing hyperparameters\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "# defining class names and mapping\n",
        "CLASS_NAMES = ['NORMAL', 'PNEUMONIA']\n",
        "CLASS_MAPPING = {\n",
        "    'NORMAL': 0,\n",
        "    'PNEUMONIA': 1\n",
        "}\n",
        "\n",
        "# creating training augmentation generator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    brightness_range=[0.9, 1.1],\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.15\n",
        ")\n",
        "\n",
        "# creating test generator without augmentation\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "\n",
        "# defining dataset directory paths\n",
        "train_dir = os.path.join(path, 'chest_xray', 'train')\n",
        "test_dir = os.path.join(path, 'chest_xray', 'test')\n",
        "val_dir = os.path.join(path, 'chest_xray', 'val')\n",
        "\n",
        "# checking dataset folder availability\n",
        "print(\"\\nChecking directories:\")\n",
        "print(f\"Train dir exists: {os.path.exists(train_dir)}\")\n",
        "print(f\"Test dir exists: {os.path.exists(test_dir)}\")\n",
        "print(f\"Val dir exists: {os.path.exists(val_dir)}\")\n",
        "\n",
        "# creating training generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical' if NUM_CLASSES > 2 else 'binary',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# creating validation generator\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical' if NUM_CLASSES > 2 else 'binary',\n",
        "    subset='validation',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# creating test generator\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical' if NUM_CLASSES > 2 else 'binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# printing sample counts and discovered classes\n",
        "print(f\"\\nTraining samples: {train_generator.samples}\")\n",
        "print(f\"Validation samples: {validation_generator.samples}\")\n",
        "print(f\"Test samples: {test_generator.samples}\")\n",
        "print(f\"Classes found: {train_generator.class_indices}\")\n",
        "\n",
        "# STEP 5: DEFINE MODEL ARCHITECTURES\n",
        "\n",
        "# defining simple baseline CNN\n",
        "def create_baseline_cnn(input_shape=(224, 224, 3), num_classes=2):\n",
        "    \"\"\"Simple CNN baseline\"\"\"\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1 if num_classes == 2 else num_classes,\n",
        "                    activation='sigmoid' if num_classes == 2 else 'softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# defining transfer learning constructor\n",
        "def create_transfer_model(base_model_name, input_shape=(224, 224, 3), num_classes=2):\n",
        "    \"\"\"Create transfer learning model\"\"\"\n",
        "    # loading chosen pretrained backbone\n",
        "    if base_model_name == 'MobileNetV2':\n",
        "        base = tf.keras.applications.MobileNetV2(\n",
        "            input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    elif base_model_name == 'EfficientNetB0':\n",
        "        base = tf.keras.applications.EfficientNetB0(\n",
        "            input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    elif base_model_name == 'ResNet50':\n",
        "        base = tf.keras.applications.ResNet50(\n",
        "            input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    elif base_model_name == 'Xception':\n",
        "        base = tf.keras.applications.Xception(\n",
        "            input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    elif base_model_name == 'InceptionV3':\n",
        "        base = tf.keras.applications.InceptionV3(\n",
        "            input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model: {base_model_name}\")\n",
        "\n",
        "    # freezing pretrained layers\n",
        "    base.trainable = False\n",
        "\n",
        "    # adding classification head\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = base(inputs, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(1 if num_classes == 2 else num_classes,\n",
        "                          activation='sigmoid' if num_classes == 2 else 'softmax')(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# STEP 6: TRAINING AND EVALUATION FUNCTION\n",
        "\n",
        "# defining routine for training and evaluating models\n",
        "def train_and_evaluate(model, model_name, train_gen, val_gen, test_gen):\n",
        "    \"\"\"Train model and return results\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {model_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    # compiling model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy' if NUM_CLASSES == 2 else 'categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # configuring early stopping\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss', patience=5, restore_best_weights=True\n",
        "    )\n",
        "\n",
        "    # training model and tracking time\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=EPOCHS,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=[early_stop],\n",
        "        verbose=1\n",
        "    )\n",
        "    training_time = (time.time() - start_time) / 60\n",
        "\n",
        "    # evaluating on test set\n",
        "    print(\"\\nEvaluating on test set...\")\n",
        "    test_loss, test_acc = model.evaluate(test_gen, verbose=0)\n",
        "\n",
        "    # generating predictions\n",
        "    predictions = model.predict(test_gen)\n",
        "    if NUM_CLASSES == 2:\n",
        "        y_pred = (predictions > 0.5).astype(int).flatten()\n",
        "        y_true = test_gen.classes\n",
        "    else:\n",
        "        y_pred = np.argmax(predictions, axis=1)\n",
        "        y_true = test_gen.classes\n",
        "\n",
        "    # computing F1 metrics\n",
        "    if NUM_CLASSES == 2:\n",
        "        f1_per_class = [\n",
        "            f1_score(y_true == 0, y_pred == 0),\n",
        "            f1_score(y_true == 1, y_pred == 1)\n",
        "        ]\n",
        "        f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "    else:\n",
        "        f1_per_class = f1_score(y_true, y_pred, average=None).tolist()\n",
        "        f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # computing confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # preparing results for export\n",
        "    results = {\n",
        "        'dataset_name': DATASET_NAME,\n",
        "        'country_income': COUNTRY_INCOME_LEVEL,\n",
        "        'model_name': model_name,\n",
        "        'num_classes': NUM_CLASSES,\n",
        "        'class_names': CLASS_NAMES,\n",
        "        'f1_per_class': f1_per_class,\n",
        "        'f1_weighted': float(f1_weighted),\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'training_time_minutes': float(training_time),\n",
        "        'num_images_train': train_gen.samples,\n",
        "        'num_images_val': val_gen.samples,\n",
        "        'num_images_test': test_gen.samples,\n",
        "        'num_parameters': int(model.count_params()),\n",
        "        'test_accuracy': float(test_acc),\n",
        "        'epochs_trained': len(history.history['loss'])\n",
        "    }\n",
        "\n",
        "    # printing results summary\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"F1 Scores per class: {f1_per_class}\")\n",
        "    print(f\"Weighted F1 Score: {f1_weighted:.4f}\")\n",
        "    print(f\"Training time: {training_time:.2f} minutes\")\n",
        "    print(f\"Parameters: {model.count_params():,}\")\n",
        "\n",
        "    # saving results to JSON\n",
        "    filename = f'/content/drive/MyDrive/xray_research_results/{DATASET_NAME}_{COUNTRY_INCOME_LEVEL}_{model_name}_results.json'\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"Results saved to: {filename}\")\n",
        "\n",
        "    # clearing model from memory\n",
        "    del model\n",
        "    tf.keras.backend.clear_session()\n",
        "    gc.collect()\n",
        "\n",
        "    return results\n",
        "\n",
        "# STEP 7: TRAIN ALL MODELS\n",
        "\n",
        "# storing results for all runs\n",
        "all_results = []\n",
        "\n",
        "# training baseline CNN\n",
        "model = create_baseline_cnn(num_classes=NUM_CLASSES)\n",
        "results = train_and_evaluate(model, 'BaselineCNN', train_generator, validation_generator, test_generator)\n",
        "all_results.append(results)\n",
        "\n",
        "# training MobileNetV2\n",
        "model = create_transfer_model('MobileNetV2', num_classes=NUM_CLASSES)\n",
        "results = train_and_evaluate(model, 'MobileNetV2', train_generator, validation_generator, test_generator)\n",
        "all_results.append(results)\n",
        "\n",
        "# training EfficientNetB0\n",
        "model = create_transfer_model('EfficientNetB0', num_classes=NUM_CLASSES)\n",
        "results = train_and_evaluate(model, 'EfficientNetB0', train_generator, validation_generator, test_generator)\n",
        "all_results.append(results)\n",
        "\n",
        "# training ResNet50\n",
        "model = create_transfer_model('ResNet50', num_classes=NUM_CLASSES)\n",
        "results = train_and_evaluate(model, 'ResNet50', train_generator, validation_generator, test_generator)\n",
        "all_results.append(results)\n",
        "\n",
        "# Optional models (decided not to do these models since the 4 models were more than sufficient for a project of this scale)\n",
        "# model = create_transfer_model('Xception', num_classes=NUM_CLASSES)\n",
        "# results = train_and_evaluate(model, 'Xception', train_generator, validation_generator, test_generator)\n",
        "# all_results.append(results)\n",
        "\n",
        "# model = create_transfer_model('InceptionV3', num_classes=NUM_CLASSES)\n",
        "# results = train_and_evaluate(model, 'InceptionV3', train_generator, validation_generator, test_generator)\n",
        "# all_results.append(results)\n",
        "\n",
        "# STEP 8: SUMMARY\n",
        "# printing final summary of all models\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETE - SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for result in all_results:\n",
        "    print(f\"\\n{result['model_name']}:\")\n",
        "    print(f\"  Weighted F1: {result['f1_weighted']:.4f}\")\n",
        "    print(f\"  Training Time: {result['training_time_minutes']:.2f} min\")\n",
        "    print(f\"  Parameters: {result['num_parameters']:,}\")\n",
        "\n",
        "print(f\"\\nAll results saved to: /content/drive/MyDrive/xray_research_results/\")"
      ]
    }
  ]
}